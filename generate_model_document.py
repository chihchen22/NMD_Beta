"""
Model Development Document Generator
=====================================
Automatically generates SR11-7 compliant model development documentation
from model outputs and configuration.

Author: Chih L. Chen, BTRM, CFA, FRM
Created: January 2026

Usage:
    python generate_model_document.py [--output OUTPUT_PATH] [--config CONFIG_PATH]
    
Example:
    python generate_model_document.py --output outputs/Model_Development_Document.md
"""

import os
import sys
import json
import argparse
from datetime import datetime
from pathlib import Path
import pandas as pd
import numpy as np

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


class ModelDocumentGenerator:
    """
    Generates model development documents from templates and model outputs.
    
    This generator reads model results from CSV files and populates a 
    markdown template to create SR11-7 compliant documentation.
    """
    
    def __init__(self, config_path: str = None, output_dir: str = "outputs"):
        """
        Initialize the document generator.
        
        Parameters
        ----------
        config_path : str, optional
            Path to JSON configuration file with document metadata
        output_dir : str
            Directory containing model output files
        """
        self.output_dir = Path(output_dir)
        self.template_dir = Path("templates")
        self.config = self._load_config(config_path)
        self.model_results = {}
        
    def _load_config(self, config_path: str) -> dict:
        """Load configuration from JSON file or return defaults."""
        default_config = {
            # Document Metadata
            "model_name": "Money Market Deposit Account Dynamic Beta Repricing Model",
            "model_type": "Interest Rate Risk - Deposit Repricing",
            "model_owner": "[Author Name]",
            "department": "Asset Liability Management / Treasury",
            "document_version": "1.0",
            "review_status": "Draft - Pending MRM Review",
            "distribution_list": "Model Risk Management, ALM, Treasury, Risk Management",
            
            # Model Configuration
            "recommended_model": "Volatility-Adjusted",
            "dependent_variable": "ILMDHYLD",
            "primary_driver": "FEDL01",
            
            # Sample Information
            "sample_start": "January 2017",
            "sample_end": "March 2025",
            "data_frequency": "Monthly end-of-period values",
            
            # Data Sources
            "data_sources": [
                {"variable": "ILMDHYLD", "source": "Bloomberg/Bankrate", "description": "High-yield MMDA rate", "role": "Dependent variable"},
                {"variable": "FEDL01", "source": "FRED/Bloomberg", "description": "Federal Funds Effective Rate", "role": "Primary driver"},
                {"variable": "FHLK3MSPRD", "source": "Bloomberg", "description": "FHLB vs SOFR 3M liquidity premium", "role": "Funding stress indicator"},
                {"variable": "1Y_3M_SPRD", "source": "Bloomberg", "description": "1Y-3M SOFR OIS term spread", "role": "Yield curve slope"},
                {"variable": "Vol_24m", "source": "Calculated", "description": "24-month rolling volatility", "role": "Uncertainty measure"}
            ],
            
            # Parameter Bounds
            "parameter_bounds": [
                {"parameter": "Œ≤_min", "lower": "0.25", "upper": "0.40", "rationale": "Minimum competitive response"},
                {"parameter": "Œ≤_max", "lower": "0.50", "upper": "0.70", "rationale": "Maximum sustainable passthrough"},
                {"parameter": "k", "lower": "0.01", "upper": "5.00", "rationale": "Moderate transition speed"},
                {"parameter": "m", "lower": "0.50", "upper": "5.00", "rationale": "Observable rate range"},
                {"parameter": "Œª", "lower": "0.00", "upper": "1.00", "rationale": "Bounded volatility effect"}
            ],
            
            # Stakeholders
            "primary_stakeholders": [
                "**Asset Liability Management (ALM):** Primary business user for NII and EVE calculations",
                "**Treasury:** Interest rate risk assessment and hedging decisions",
                "**Finance:** Earnings forecasting and budgeting processes",
                "**Risk Management:** IRRBB reporting and regulatory stress testing"
            ],
            "secondary_stakeholders": [
                "**Model Risk Management:** Model validation and governance oversight",
                "**Internal Audit:** Model control testing and compliance verification",
                "**Regulatory Relations:** Examination support and regulatory reporting",
                "**Technology:** Model implementation and system integration"
            ],
            
            # Use Cases
            "primary_use_cases": [
                "Net Interest Income (NII) sensitivity analysis and forecasting",
                "Economic Value of Equity (EVE) calculations for IRRBB reporting",
                "Duration estimation for non-maturity deposit portfolios",
                "Regulatory stress testing (CCAR, DFAST, Basel III IRRBB)",
                "Funds Transfer Pricing (FTP) framework calibration",
                "Asset-liability management strategic planning"
            ],
            
            # Visualization paths
            "fig_data_dashboard": "outputs/visualizations/01_data_dashboard.png",
            "fig_model_fit": "outputs/visualizations/02_model_fit_comparison.png",
            "fig_beta_evolution": "outputs/visualizations/03_beta_evolution.png",
            "fig_residual_analysis": "outputs/visualizations/04_residual_analysis_vol_adjusted.png"
        }
        
        if config_path and os.path.exists(config_path):
            with open(config_path, 'r') as f:
                user_config = json.load(f)
                default_config.update(user_config)
                
        return default_config
    
    def load_model_results(self):
        """Load all model results from output CSV files."""
        
        # Load parameter estimates
        param_file = self.output_dir / "model_results" / "parameter_estimates.csv"
        if param_file.exists():
            self.model_results['parameters'] = pd.read_csv(param_file)
            
        # Load performance comparison
        perf_file = self.output_dir / "model_results" / "model_performance_comparison.csv"
        if perf_file.exists():
            self.model_results['performance'] = pd.read_csv(perf_file)
            
        # Load diagnostic tests
        diag_file = self.output_dir / "model_results" / "diagnostic_tests.csv"
        if diag_file.exists():
            self.model_results['diagnostics'] = pd.read_csv(diag_file)
            
        # Load beta values by rate
        beta_file = self.output_dir / "model_results" / "beta_values_by_rate.csv"
        if beta_file.exists():
            self.model_results['beta_by_rate'] = pd.read_csv(beta_file)
            
        # Load descriptive statistics
        desc_file = self.output_dir / "data" / "descriptive_statistics.csv"
        if desc_file.exists():
            self.model_results['descriptive_stats'] = pd.read_csv(desc_file)
            
        # Load likelihood ratio tests
        lr_file = self.output_dir / "model_results" / "likelihood_ratio_tests.csv"
        if lr_file.exists():
            self.model_results['lr_tests'] = pd.read_csv(lr_file)
            
        # Load processed data for observation count
        data_file = self.output_dir / "data" / "processed_data.csv"
        if data_file.exists():
            self.model_results['data'] = pd.read_csv(data_file)
            
        return self
    
    def _format_table_row(self, values: list) -> str:
        """Format a list of values as a markdown table row."""
        return "| " + " | ".join(str(v) for v in values) + " |"
    
    def _format_bullet_list(self, items: list) -> str:
        """Format a list of items as markdown bullets."""
        return "\n".join(f"- {item}" for item in items)
    
    def _get_parameter_estimates_table(self) -> str:
        """Generate parameter estimates table from model results."""
        if 'parameters' not in self.model_results:
            return "| Parameter | Estimate | Interpretation |\n|-----------|----------|----------------|\n| Data not available | | |"
        
        df = self.model_results['parameters']
        # Filter for recommended model
        rec_model = self.config.get('recommended_model', 'Volatility-Adjusted')
        
        # Try to find model column
        model_cols = [c for c in df.columns if 'model' in c.lower()]
        if model_cols:
            df = df[df[model_cols[0]].str.contains(rec_model, case=False, na=False)]
        
        rows = []
        interpretations = {
            'alpha': 'Base margin when Fed Funds = 0%',
            'k': 'Transition steepness parameter',
            'm': 'Inflection point (competition threshold)',
            'beta_min': 'Minimum deposit sensitivity',
            'beta_max': 'Maximum deposit sensitivity',
            'gamma_fhlb': 'Liquidity premium effect',
            'gamma_term': 'Term structure effect',
            'lambda': 'Volatility dampening factor'
        }
        
        for _, row in df.iterrows():
            param = str(row.get('Parameter', row.get('parameter', '')))
            estimate = row.get('Estimate', row.get('estimate', row.get('Value', '')))
            if pd.notna(estimate):
                if isinstance(estimate, float):
                    estimate = f"{estimate:.4f}"
                interp = interpretations.get(param.lower().replace('_', ''), '')
                rows.append(f"| {param} | {estimate} | {interp} |")
        
        if rows:
            return "\n".join(rows)
        return "| Data not available | | |"
    
    def _get_performance_table(self) -> str:
        """Generate model performance comparison table."""
        if 'performance' not in self.model_results:
            return "| Model | R¬≤ | Adj R¬≤ | RMSE (%) | AIC | BIC | Out-of-Sample RMSE |\n|-------|----|---------|---------|-----|-----|-------------------|\n| Data not available | | | | | | |"
        
        df = self.model_results['performance']
        rows = []
        rec_model = self.config.get('recommended_model', 'Volatility-Adjusted')
        
        for _, row in df.iterrows():
            model_name = str(row.get('Model', row.get('model', '')))
            
            # Bold the recommended model
            if rec_model.lower() in model_name.lower():
                model_name = f"**{model_name}**"
            
            r2 = row.get('R_squared', row.get('R2', row.get('r_squared', '')))
            adj_r2 = row.get('Adj_R_squared', row.get('Adj_R2', row.get('adj_r_squared', '')))
            rmse = row.get('RMSE', row.get('rmse', ''))
            aic = row.get('AIC', row.get('aic', ''))
            bic = row.get('BIC', row.get('bic', ''))
            oos_rmse = row.get('Recent_RMSE', row.get('OOS_RMSE', row.get('recent_rmse', '')))
            
            # Format numeric values
            def fmt(v, decimals=4):
                if pd.isna(v) or v == '':
                    return ''
                try:
                    return f"{float(v):.{decimals}f}"
                except:
                    return str(v)
            
            rows.append(f"| {model_name} | {fmt(r2)} | {fmt(adj_r2)} | {fmt(rmse)} | {fmt(aic, 1)} | {fmt(bic, 1)} | {fmt(oos_rmse)} |")
        
        if rows:
            return "\n".join(rows)
        return "| Data not available | | | | | | |"
    
    def _get_diagnostic_table(self) -> str:
        """Generate diagnostic test results table."""
        if 'diagnostics' not in self.model_results:
            return "| Test | p-value | Result |\n|------|---------|--------|\n| Data not available | | |"
        
        df = self.model_results['diagnostics']
        rows = []
        
        for _, row in df.iterrows():
            test = row.get('Test', row.get('test', ''))
            
            # Get p-values for each model
            vol_p = row.get('Vol_Adjusted_p', row.get('Volatility-Adjusted', ''))
            enh_p = row.get('Enhanced_p', row.get('Enhanced', ''))
            quad_p = row.get('Quadratic_p', row.get('Quadratic', ''))
            
            def fmt_p(p):
                if pd.isna(p) or p == '':
                    return ''
                try:
                    pval = float(p)
                    result = "‚úì" if pval > 0.05 else "‚úó"
                    return f"p = {pval:.3f} {result}"
                except:
                    return str(p)
            
            rows.append(f"| {test} | {fmt_p(vol_p)} | {fmt_p(enh_p)} | {fmt_p(quad_p)} |")
        
        if rows:
            return "\n".join(rows)
        return "| Data not available | | | |"
    
    def _get_beta_by_rate_table(self) -> str:
        """Generate beta values by rate level table."""
        if 'beta_by_rate' not in self.model_results:
            return "| Rate Level | Beta Value |\n|------------|------------|\n| Data not available | |"
        
        df = self.model_results['beta_by_rate']
        rows = []
        
        # Select key rate levels
        key_rates = [0.0, 1.0, 2.0, 3.0, 4.0, 5.0]
        
        for rate in key_rates:
            rate_col = [c for c in df.columns if 'rate' in c.lower() or 'fed' in c.lower()]
            beta_col = [c for c in df.columns if 'beta' in c.lower() and 'vol' in c.lower()]
            
            if rate_col and beta_col:
                mask = df[rate_col[0]].round(1) == rate
                if mask.any():
                    beta_val = df.loc[mask, beta_col[0]].values[0]
                    rows.append(f"| {rate:.1f}% | {beta_val:.2%} |")
        
        if rows:
            return "\n".join(rows)
        return "| Data not available | |"
    
    def _get_descriptive_stats_table(self) -> str:
        """Generate descriptive statistics table."""
        if 'descriptive_stats' not in self.model_results:
            return "| Variable | Mean | Std. Dev. | Min | Max |\n|----------|------|-----------|-----|-----|\n| Data not available | | | | |"
        
        df = self.model_results['descriptive_stats']
        rows = []
        
        for _, row in df.iterrows():
            var = row.get('Variable', row.get('variable', ''))
            mean = row.get('Mean', row.get('mean', ''))
            std = row.get('Std', row.get('std', row.get('Std_Dev', '')))
            min_val = row.get('Min', row.get('min', ''))
            max_val = row.get('Max', row.get('max', ''))
            
            def fmt(v):
                if pd.isna(v):
                    return ''
                try:
                    return f"{float(v):.2f}"
                except:
                    return str(v)
            
            rows.append(f"| {var} | {fmt(mean)} | {fmt(std)} | {fmt(min_val)} | {fmt(max_val)} |")
        
        if rows:
            return "\n".join(rows)
        return "| Data not available | | | | |"
    
    def _get_lr_tests_table(self) -> str:
        """Generate likelihood ratio tests table."""
        if 'lr_tests' not in self.model_results:
            return "| Comparison | LR Statistic | p-value | Result |\n|------------|--------------|---------|--------|\n| Data not available | | | |"
        
        df = self.model_results['lr_tests']
        rows = []
        
        for _, row in df.iterrows():
            comparison = row.get('Comparison', row.get('comparison', ''))
            lr_stat = row.get('LR_Statistic', row.get('lr_statistic', row.get('LR_stat', '')))
            p_val = row.get('p_value', row.get('P_value', ''))
            
            def fmt(v, decimals=2):
                if pd.isna(v):
                    return ''
                try:
                    return f"{float(v):.{decimals}f}"
                except:
                    return str(v)
            
            # Determine result
            try:
                result = "Preferred" if float(p_val) < 0.05 else "No difference"
            except:
                result = ""
            
            rows.append(f"| {comparison} | {fmt(lr_stat)} | {fmt(p_val, 4)} | {result} |")
        
        if rows:
            return "\n".join(rows)
        return "| Data not available | | | |"
    
    def _get_variable_definitions_table(self) -> str:
        """Generate variable definitions table."""
        rows = []
        for var in self.config.get('data_sources', []):
            rows.append(f"| {var['variable']} | {var['source']} | {var['description']} | {var['role']} |")
        return "\n".join(rows) if rows else "| Variable | Source | Description | Role |\n| Data not configured | | | |"
    
    def _get_parameter_bounds_table(self) -> str:
        """Generate parameter bounds table."""
        rows = []
        for bound in self.config.get('parameter_bounds', []):
            rows.append(f"| {bound['parameter']} | {bound['lower']} | {bound['upper']} | {bound['rationale']} |")
        return "\n".join(rows) if rows else "| Parameter | Lower | Upper | Rationale |\n| Data not configured | | | |"
    
    def generate_document(self) -> str:
        """
        Generate the complete model development document.
        
        Returns
        -------
        str
            Complete markdown document
        """
        # Load template
        template_path = self.template_dir / "model_development_document_template.md"
        if not template_path.exists():
            raise FileNotFoundError(f"Template not found: {template_path}")
        
        with open(template_path, 'r', encoding='utf-8') as f:
            template = f.read()
        
        # Get observation count
        n_obs = len(self.model_results.get('data', pd.DataFrame()))
        if n_obs == 0:
            n_obs = 99  # Default
        
        # Calculate performance improvement
        perf_df = self.model_results.get('performance', pd.DataFrame())
        improvement_text = ""
        if not perf_df.empty:
            try:
                vol_rmse = perf_df[perf_df['Model'].str.contains('Vol', case=False, na=False)]['Recent_RMSE'].values
                enh_rmse = perf_df[perf_df['Model'].str.contains('Enhanced', case=False, na=False)]['Recent_RMSE'].values
                if len(vol_rmse) > 0 and len(enh_rmse) > 0:
                    pct_improvement = (1 - vol_rmse[0] / enh_rmse[0]) * 100
                    improvement_text = f"The model demonstrates {pct_improvement:.0f}% lower forecast errors compared to alternatives during the validation period."
            except:
                pass
        
        # Build replacements dictionary
        replacements = {
            # Metadata
            "{{MODEL_NAME}}": self.config.get('model_name', ''),
            "{{MODEL_TYPE}}": self.config.get('model_type', ''),
            "{{MODEL_OWNER}}": self.config.get('model_owner', ''),
            "{{DEPARTMENT}}": self.config.get('department', ''),
            "{{DOCUMENT_DATE}}": datetime.now().strftime("%B %d, %Y"),
            "{{DOCUMENT_VERSION}}": self.config.get('document_version', '1.0'),
            "{{REVIEW_STATUS}}": self.config.get('review_status', ''),
            "{{DISTRIBUTION_LIST}}": self.config.get('distribution_list', ''),
            "{{LAST_UPDATED}}": datetime.now().strftime("%B %d, %Y"),
            "{{NEXT_REVIEW_DATE}}": (datetime.now().replace(year=datetime.now().year + 1)).strftime("%B %d, %Y"),
            
            # Sample info
            "{{SAMPLE_PERIOD}}": f"{self.config.get('sample_start', '')} - {self.config.get('sample_end', '')}",
            "{{DATA_FREQUENCY}}": self.config.get('data_frequency', ''),
            "{{N_OBSERVATIONS}}": f"{n_obs} observations",
            
            # Recommended model
            "{{RECOMMENDED_MODEL_NAME}}": self.config.get('recommended_model', ''),
            
            # Tables from model results
            "{{PARAMETER_ESTIMATES}}": self._get_parameter_estimates_table(),
            "{{MODEL_PERFORMANCE_COMPARISON}}": self._get_performance_table(),
            "{{DIAGNOSTIC_TEST_RESULTS}}": self._get_diagnostic_table(),
            "{{BETA_BY_RATE_LEVEL}}": self._get_beta_by_rate_table(),
            "{{DESCRIPTIVE_STATISTICS}}": self._get_descriptive_stats_table(),
            "{{LIKELIHOOD_RATIO_TESTS}}": self._get_lr_tests_table(),
            "{{VARIABLE_DEFINITIONS}}": self._get_variable_definitions_table(),
            "{{PARAMETER_CONSTRAINTS}}": self._get_parameter_bounds_table(),
            
            # Lists
            "{{PRIMARY_USE_CASES}}": self._format_bullet_list(self.config.get('primary_use_cases', [])),
            "{{PRIMARY_STAKEHOLDERS}}": self._format_bullet_list(self.config.get('primary_stakeholders', [])),
            "{{SECONDARY_STAKEHOLDERS}}": self._format_bullet_list(self.config.get('secondary_stakeholders', [])),
            
            # Version control (placeholder rows)
            "{{VERSION_CONTROL_LOG}}": f"| {self.config.get('document_version', '1.0')} | {datetime.now().strftime('%B %d, %Y')} | {self.config.get('model_owner', '')} | Initial model development document | [MRM Head] |",
            "{{MODEL_VERSION_LOG}}": "| 1.0 | TBD | Initial production model | New dynamic beta capability | Under Review |",
            
            # Figures
            "{{FIG_DATA_DASHBOARD}}": self.config.get('fig_data_dashboard', ''),
            "{{FIG_MODEL_FIT}}": self.config.get('fig_model_fit', ''),
            "{{FIG_BETA_EVOLUTION}}": self.config.get('fig_beta_evolution', ''),
            "{{FIG_RESIDUAL_ANALYSIS}}": self.config.get('fig_residual_analysis', ''),
            
            # Performance summary
            "{{PERFORMANCE_SUMMARY}}": improvement_text or "See Model Performance Comparison section for detailed metrics.",
        }
        
        # Add standard content blocks
        replacements.update(self._get_standard_content_blocks())
        
        # Apply replacements
        document = template
        for placeholder, value in replacements.items():
            document = document.replace(placeholder, str(value))
        
        return document
    
    def _get_standard_content_blocks(self) -> dict:
        """Return standard content blocks for the template."""
        return {
            "{{EXECUTIVE_SUMMARY}}": """At its core, deposit beta estimation is one of the most critical challenges in bank asset-liability management. Traditional static beta models assume a constant pass-through rate from policy benchmarks to deposit rates‚Äîan assumption that the Federal Reserve's aggressive tightening cycle beginning in 2022 has thoroughly exposed as inadequate. This document presents a volatility-adjusted dynamic beta model for money market deposit account (MMDA) repricing that addresses these fundamental limitations.

The model captures how deposit betas evolve with interest rate levels‚Äîa phenomenon grounded in the "deposits channel" theory of monetary policy transmission. As rates rise, competitive pressures intensify, forcing higher pass-through rates to retain deposits. By incorporating this rate-dependent sensitivity alongside volatility adjustments, the model achieves superior predictive accuracy while maintaining the economic interpretability that ALM practitioners require and the regulatory compliance demanded by SR11-7 standards.""",

            "{{MODEL_OWNER_RESPONSIBILITIES}}": """- Model development, documentation, and maintenance
- Performance monitoring and issue escalation
- Stakeholder communication and training
- Regulatory examination support""",

            "{{BUSINESS_PROBLEM_STATEMENT}}": """Understanding how deposit rates respond to changes in market interest rates is fundamental to bank asset-liability management. This relationship‚Äîcommonly expressed as the deposit "beta"‚Äîdetermines how quickly and completely banks pass through rate changes to their depositors. Getting this right has material implications for Net Interest Income forecasting, Economic Value of Equity calculations, and ultimately, strategic balance sheet positioning.

Traditional static beta models assume a constant pass-through rate from policy benchmarks to deposit rates. While simple and intuitive, this assumption fails to capture the dynamic, nonlinear nature of deposit competition across varying interest rate environments.""",

            "{{MODEL_OBJECTIVES}}": """The dynamic beta model addresses these limitations by:

1. **Capturing Rate-Dependent Sensitivity:** Modeling how deposit betas evolve with interest rate levels
2. **Incorporating Market Conditions:** Adjusting for volatility, liquidity premiums, and term structure effects
3. **Maintaining Economic Bounds:** Ensuring realistic sensitivity estimates across all scenarios
4. **Supporting Regulatory Compliance:** Meeting SR11-7 conceptual soundness requirements""",

            "{{EXPECTED_BENEFITS}}": """- **Enhanced Risk Management:** More accurate interest rate risk assessment
- **Improved Forecasting:** Superior NII and EVE projection accuracy
- **Regulatory Alignment:** Sophisticated behavioral modeling
- **FTP Calibration:** Dynamic betas inform more accurate Funds Transfer Pricing""",

            "{{CONCEPTUAL_FOUNDATION}}": """The model is grounded in the "deposits channel" theory of monetary policy transmission (Drechsler, Savov, and Schnabl, 2017), which demonstrates that banks' market power in deposit markets varies systematically with interest rate levels. When rates are low, depositors have few alternatives; as rates rise, competitive pressures intensify.""",

            "{{CORE_MODEL_STRUCTURE}}": """**Dynamic Beta Function:**
```
Œ≤_t^level = Œ≤_min + (Œ≤_max - Œ≤_min) / (1 + exp(-k √ó (r_t - m)))
```

**Volatility Adjustment:**
```
Œ≤_t = Œ≤_t^level √ó (1 - Œª √ó œÉ_t / œÉ*)
```

**Complete Specification:**
```
Deposit_Rate_t = Œ± + Œ≤_t √ó Policy_Rate_t + Œ≥‚ÇÅ √ó Liquidity_Spread_t + Œ≥‚ÇÇ √ó Term_Spread_t + Œµ_t
```""",

            "{{MODEL_VARIANTS}}": """Three specifications were developed and compared:

1. **Enhanced Logistic Model:** Standard logistic beta without volatility adjustment
2. **Volatility-Adjusted Model (Recommended):** Full specification with volatility dampening
3. **Quadratic Model:** Flexible polynomial beta specification""",

            "{{PARAMETER_INTERPRETATION}}": """- **Œ≤_min/Œ≤_max:** Lower and upper bounds for deposit sensitivity
- **m:** Inflection point where competitive pressures intensify
- **k:** Transition steepness parameter
- **Œª:** Volatility dampening factor""",

            "{{DATA_SOURCES}}": """All time series data is extracted from Bloomberg Terminal with supplementary series from Federal Reserve Economic Data (FRED) system. Data collection follows established data governance protocols with automated quality checks.""",

            "{{DATA_QUALITY}}": """Comprehensive data validation includes:
- Missing value identification and treatment protocols
- Outlier detection using statistical thresholds
- Stationarity testing via ADF and KPSS procedures
- Data consistency checks across sources""",

            "{{ESTIMATION_METHODOLOGY}}": """Models are estimated using Maximum Likelihood Estimation (MLE) with Gaussian error assumptions. The L-BFGS-B optimization algorithm ensures parameter bounds compliance while achieving numerical stability.""",

            "{{MODEL_SELECTION_CRITERIA}}": """Evaluation employs multiple criteria:
- **Statistical Fit:** R¬≤, adjusted R¬≤, RMSE, MAE
- **Information Criteria:** AIC, BIC for model comparison
- **Economic Validity:** Parameter interpretability and bounds compliance
- **Out-of-Sample Performance:** Validation period testing
- **Diagnostic Tests:** Normality, autocorrelation, heteroscedasticity""",

            "{{BETA_EVOLUTION_DESCRIPTION}}": """The recommended model produces economically sensible beta progression across rate environments.""",

            "{{CHALLENGER_FRAMEWORK}}": """Two systematic challengers validate the recommended specification:

1. **Enhanced Logistic Model:** Primary challenger removing volatility effects
2. **Quadratic Model:** Flexible benchmarking specification""",

            "{{OUT_OF_SAMPLE_VALIDATION}}": """The model demonstrates compelling out-of-sample performance during the validation period, with significantly lower forecast errors than alternative specifications.""",

            "{{CORE_ASSUMPTIONS}}": """1. **Competitive Structure Stability:** Assumes relatively stable competitive dynamics
2. **Behavioral Consistency:** Depositor and bank behavior patterns remain consistent
3. **Policy Framework Continuity:** Conventional monetary policy framework continues
4. **Data Quality Maintenance:** Data sources remain reliable and consistent
5. **Functional Form Appropriateness:** Logistic specification adequately captures dynamics""",

            "{{DATA_LIMITATIONS}}": """- **Historical Range:** Calibrated on limited historical data; extrapolation requires caution
- **Sample Period:** Limited experience with extreme rate environments
- **Data Frequency:** Monthly frequency may miss intra-month dynamics""",

            "{{STRUCTURAL_LIMITATIONS}}": """- **Industry Disruption:** May not capture fintech competition or digital banking innovations
- **Regulatory Changes:** Assumes stable deposit insurance and regulatory frameworks
- **Economic Regime Changes:** Performance may degrade during unprecedented conditions""",

            "{{TECHNICAL_LIMITATIONS}}": """- **Parameter Uncertainty:** Estimates subject to statistical uncertainty
- **Computational Requirements:** Requires sophisticated optimization systems
- **Implementation Complexity:** More complex than static models""",

            "{{RECOMMENDED_APPLICATIONS}}": """- NII sensitivity analysis within historical rate ranges
- EVE calculations for IRRBB reporting
- Regulatory stress testing scenarios
- ALM strategic planning and duration estimation""",

            "{{USE_RESTRICTIONS}}": """- **Scenario Limitations:** Apply uncertainty adjustments for extreme rates
- **Time Horizon:** Most reliable for quarterly to annual forecasting
- **Stress Testing:** Consider overlay adjustments for tail risk scenarios
- **Product Scope:** Calibrated specifically for high-yield MMDAs""",

            "{{CONCEPTUAL_SOUNDNESS}}": """The model demonstrates conceptual soundness through:
- **Theoretical Foundation:** Grounded in established economic literature
- **Empirical Validation:** Comprehensive statistical testing
- **Economic Interpretation:** All parameters admit clear business interpretation
- **Bounded Results:** Parameter constraints ensure economically plausible outcomes""",

            "{{MODEL_DOCUMENTATION}}": """Complete documentation includes:
- Development methodology and estimation procedures
- Data sources and variable definitions
- Validation results and diagnostics
- Limitation identification and use guidelines""",

            "{{MONITORING_FRAMEWORK}}": """Systematic monitoring includes:
- **Performance Tracking:** Monthly accuracy metrics
- **Parameter Stability:** Quarterly rolling window analysis
- **Diagnostic Testing:** Ongoing residual analysis
- **Challenger Maintenance:** Regular benchmarking""",

            "{{GOVERNANCE_STRUCTURE}}": """**Model Risk Committee:** Quarterly model performance review
**Asset Liability Committee (ALCO):** Monthly model output review
**Model Validation Unit:** Independent annual validation
**Model Owner:** Ongoing monitoring and maintenance""",

            "{{APPROVAL_FRAMEWORK}}": """**Level 1 - Parameter Refresh:** Minor recalibration within bounds
**Level 2 - Methodology Enhancement:** Material specification changes
**Level 3 - Model Replacement:** Fundamental changes requiring full validation""",

            "{{CHANGE_MANAGEMENT}}": """1. **Change Request:** Formal documentation of proposed modifications
2. **Impact Assessment:** Analysis of effects on outputs and applications
3. **Validation Review:** Independent assessment
4. **Stakeholder Approval:** Business and risk management sign-off
5. **Implementation:** Controlled rollout with parallel testing
6. **Post-Implementation Review:** Performance validation""",

            "{{TECHNOLOGY_REQUIREMENTS}}": """**Data Infrastructure:**
- Real-time data feed connectivity
- Automated data quality checking
- Historical data storage with version control

**Computational Environment:**
- Python 3.8+ with scientific computing libraries
- Optimization packages (scipy, statsmodels)
- Visualization capabilities""",

            "{{IMPLEMENTATION_TIMELINE}}": """**Phase 1 (Months 1-2):** Infrastructure setup and parallel testing
**Phase 2 (Months 3-4):** User training and system integration
**Phase 3 (Months 5-6):** Production rollout with monitoring
**Phase 4 (Months 7+):** Full deployment and optimization""",

            "{{TRAINING_REQUIREMENTS}}": """- **Model Methodology:** Understanding of dynamic beta concepts
- **System Operation:** Technical implementation and output interpretation
- **Risk Management:** Appropriate use guidelines and limitations
- **Troubleshooting:** Issue identification and escalation""",

            "{{QUALITY_ASSURANCE}}": """- **Code Testing:** Comprehensive unit and integration testing
- **Output Validation:** Comparison with benchmarks
- **User Acceptance:** Business stakeholder sign-off
- **Performance Monitoring:** Ongoing accuracy tracking""",

            "{{PERFORMANCE_METRICS}}": """**Accuracy Measures:**
- Mean Absolute Error (MAE)
- Root Mean Square Error (RMSE)
- Directional Accuracy
- Bias Analysis

**Stability Indicators:**
- Parameter Drift
- Confidence Intervals
- Structural Break Tests""",

            "{{MONITORING_FRAMEWORK_DETAIL}}": """**Daily:** Data quality validation and exception reporting
**Monthly:** Performance dashboard and stakeholder communication
**Quarterly:** Comprehensive assessment and challenger comparison
**Annual:** Independent validation and strategic planning""",

            "{{EXCEPTION_MANAGEMENT}}": """**Performance Degradation:** Automatic alerts when metrics exceed thresholds
**Parameter Instability:** Formal review triggered by significant drift
**Data Quality Issues:** Immediate investigation and resolution
**System Failures:** Contingency procedures and backup deployment""",

            "{{REPORTING_COMMUNICATION}}": """- **Executive Dashboard:** Monthly summary for senior management
- **Risk Committee Reports:** Quarterly comprehensive review
- **User Updates:** Ongoing communication of changes
- **Regulatory Documentation:** Annual validation reports""",

            "{{ACKNOWLEDGMENTS}}": """This model and supporting research was developed with assistance from AI systems, including Perplexity Labs AI agents, Google Gemini Pro 2.5, and Anthropic Claude for various aspects of data analysis, statistical testing, code development, and documentation preparation.

It is essential to emphasize that while AI assistance accelerated the technical development process, all economic reasoning, model specification choices, parameter interpretation, and business application recommendations reflect the professional judgment of the model owner. The AI systems served as sophisticated computational tools rather than autonomous decision-makers.

**Specific AI Contributions:**
- Python code implementation and optimization
- Statistical test execution and output formatting
- Documentation drafting and consistency checking

**Human-Driven Elements:**
- Model conceptual framework and theoretical grounding
- Economic interpretation of results
- Parameter bounds selection based on banking expertise
- Business application recommendations""",

            "{{REPRODUCIBILITY_APPENDIX}}": """All model results presented in this document are fully reproducible. The following artifacts are maintained in the project repository:

**Data Files:**
- `outputs/data/processed_data.csv` - Processed dataset
- `outputs/data/descriptive_statistics.csv` - Variable summary statistics

**Model Results:**
- `outputs/model_results/parameter_estimates.csv` - All parameter estimates
- `outputs/model_results/model_performance_comparison.csv` - Performance metrics
- `outputs/model_results/diagnostic_tests.csv` - Diagnostic test results
- `outputs/model_results/beta_values_by_rate.csv` - Beta schedule

**Visualizations:**
- `outputs/visualizations/` - All model visualizations

**Code:**
- `mmda_dynamic_beta_model_complete.py` - Complete model implementation
- `run_analysis_with_outputs.py` - Reproducible analysis script

To reproduce all results: `python run_analysis_with_outputs.py`"""
        }
    
    def save_document(self, output_path: str = None):
        """
        Generate and save the document to file.
        
        Parameters
        ----------
        output_path : str, optional
            Output file path. Defaults to outputs/Model_Development_Document.md
        """
        if output_path is None:
            output_path = self.output_dir / "Model_Development_Document.md"
        
        document = self.generate_document()
        
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(document)
        
        print(f"‚úì Document generated: {output_path}")
        return output_path


def create_sample_config(output_path: str = "config/document_config.json"):
    """
    Create a sample configuration file for customization.
    
    Parameters
    ----------
    output_path : str
        Path to save the sample configuration
    """
    sample_config = {
        "model_name": "Money Market Deposit Account Dynamic Beta Repricing Model",
        "model_type": "Interest Rate Risk - Deposit Repricing",
        "model_owner": "Your Name",
        "department": "Asset Liability Management / Treasury",
        "document_version": "1.0",
        "review_status": "Draft - Pending MRM Review",
        "distribution_list": "Model Risk Management, ALM, Treasury, Risk Management",
        "recommended_model": "Volatility-Adjusted",
        "sample_start": "January 2017",
        "sample_end": "March 2025",
        "data_frequency": "Monthly end-of-period values",
        "fig_data_dashboard": "outputs/visualizations/01_data_dashboard.png",
        "fig_model_fit": "outputs/visualizations/02_model_fit_comparison.png",
        "fig_beta_evolution": "outputs/visualizations/03_beta_evolution.png",
        "fig_residual_analysis": "outputs/visualizations/04_residual_analysis_vol_adjusted.png"
    }
    
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w') as f:
        json.dump(sample_config, f, indent=2)
    
    print(f"‚úì Sample configuration created: {output_path}")
    return output_path


def main():
    """Main entry point for document generation."""
    parser = argparse.ArgumentParser(
        description="Generate SR11-7 compliant model development documentation"
    )
    parser.add_argument(
        '--output', '-o',
        default='outputs/Model_Development_Document.md',
        help='Output file path for generated document'
    )
    parser.add_argument(
        '--config', '-c',
        default=None,
        help='Path to JSON configuration file'
    )
    parser.add_argument(
        '--create-config',
        action='store_true',
        help='Create a sample configuration file'
    )
    parser.add_argument(
        '--output-dir',
        default='outputs',
        help='Directory containing model output files'
    )
    
    args = parser.parse_args()
    
    if args.create_config:
        create_sample_config()
        return
    
    print("=" * 60)
    print("Model Development Document Generator")
    print("=" * 60)
    
    # Initialize generator
    generator = ModelDocumentGenerator(
        config_path=args.config,
        output_dir=args.output_dir
    )
    
    # Load model results
    print("\nüìä Loading model results...")
    generator.load_model_results()
    
    # Generate and save document
    print("üìù Generating document...")
    output_path = generator.save_document(args.output)
    
    print("\n" + "=" * 60)
    print("‚úì Document generation complete!")
    print(f"  Output: {output_path}")
    print("=" * 60)


if __name__ == "__main__":
    main()
